{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "\n",
    "```\n",
    "\n",
    "DATA COLUMNS:\n",
    "marketplace       - 2 letter country code of the marketplace where the review was written.\n",
    "customer_id       - Random identifier that can be used to aggregate reviews written by a single author.\n",
    "review_id         - The unique ID of the review.\n",
    "product_id        - The unique Product ID the review pertains to. In the multilingual dataset the reviews\n",
    "                    for the same product in different countries can be grouped by the same product_id.\n",
    "product_parent    - Random identifier that can be used to aggregate reviews for the same product.\n",
    "product_title     - Title of the product.\n",
    "product_category  - Broad product category that can be used to group reviews \n",
    "                    (also used to group the dataset into coherent parts).\n",
    "star_rating       - The 1-5 star rating of the review.\n",
    "helpful_votes     - Number of helpful votes.\n",
    "total_votes       - Number of total votes the review received.\n",
    "vine              - Review was written as part of the Vine program.\n",
    "verified_purchase - The review is on a verified purchase.\n",
    "review_headline   - The title of the review.\n",
    "review_body       - The review text.\n",
    "review_date       - The date the review was written.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:55:34.639646Z",
     "start_time": "2021-04-01T08:55:33.954152Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1925: expected 15 fields, saw 22\\nSkipping line 1977: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('amazon_reviews_us_Grocery_v1_00.tsv.gz', \n",
    "                 nrows=20000, sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:58:09.608155Z",
     "start_time": "2021-04-01T08:58:09.594260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>42521656</td>\n",
       "      <td>R26MV8D0KG6QI6</td>\n",
       "      <td>B000SAQCWC</td>\n",
       "      <td>159713740</td>\n",
       "      <td>The Cravings Place Chocolate Chunk Cookie Mix,...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Using these for years - love them.</td>\n",
       "      <td>As a family allergic to wheat, dairy, eggs, nu...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>12049833</td>\n",
       "      <td>R1OF8GP57AQ1A0</td>\n",
       "      <td>B00509LVIQ</td>\n",
       "      <td>138680402</td>\n",
       "      <td>Mauna Loa Macadamias, 11 Ounce Packages</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>My favorite nut.  Creamy, crunchy, salty, and ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>107642</td>\n",
       "      <td>R3VDC1QB6MC4ZZ</td>\n",
       "      <td>B00KHXESLC</td>\n",
       "      <td>252021703</td>\n",
       "      <td>Organic Matcha Green Tea Powder - 100% Pure Ma...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>This green tea tastes so good! My girlfriend l...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>6042304</td>\n",
       "      <td>R12FA3DCF8F9ER</td>\n",
       "      <td>B000F8JIIC</td>\n",
       "      <td>752728342</td>\n",
       "      <td>15oz Raspberry Lyons Designer Dessert Syrup Sauce</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>I love Melissa's brand but this is a great sec...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>18123821</td>\n",
       "      <td>RTWHVNV6X4CNJ</td>\n",
       "      <td>B004ZWR9RQ</td>\n",
       "      <td>552138758</td>\n",
       "      <td>Stride Spark Kinetic Fruit Sugar Free Gum, 14-...</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>good</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     42521656  R26MV8D0KG6QI6  B000SAQCWC       159713740   \n",
       "1          US     12049833  R1OF8GP57AQ1A0  B00509LVIQ       138680402   \n",
       "2          US       107642  R3VDC1QB6MC4ZZ  B00KHXESLC       252021703   \n",
       "3          US      6042304  R12FA3DCF8F9ER  B000F8JIIC       752728342   \n",
       "4          US     18123821   RTWHVNV6X4CNJ  B004ZWR9RQ       552138758   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  The Cravings Place Chocolate Chunk Cookie Mix,...          Grocery   \n",
       "1            Mauna Loa Macadamias, 11 Ounce Packages          Grocery   \n",
       "2  Organic Matcha Green Tea Powder - 100% Pure Ma...          Grocery   \n",
       "3  15oz Raspberry Lyons Designer Dessert Syrup Sauce          Grocery   \n",
       "4  Stride Spark Kinetic Fruit Sugar Free Gum, 14-...          Grocery   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            5              0            0    N                 N   \n",
       "3            5              0            0    N                 Y   \n",
       "4            5              0            0    N                 Y   \n",
       "\n",
       "                      review_headline  \\\n",
       "0  Using these for years - love them.   \n",
       "1                           Wonderful   \n",
       "2                          Five Stars   \n",
       "3                          Five Stars   \n",
       "4                          Five Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  As a family allergic to wheat, dairy, eggs, nu...  2015-08-31  \n",
       "1  My favorite nut.  Creamy, crunchy, salty, and ...  2015-08-31  \n",
       "2  This green tea tastes so good! My girlfriend l...  2015-08-31  \n",
       "3  I love Melissa's brand but this is a great sec...  2015-08-31  \n",
       "4                                               good  2015-08-31  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-12cddd223a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'safety'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "for title in df['review_body']:\n",
    "    if 'safety' in title:\n",
    "        print('yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-1-c3b6d32fc640>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c3b6d32fc640>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    df = pd.concat([top_row, df]).reset_index(drop = True)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Concat with old DataFrame and reset the Index.\n",
    "\n",
    "df = pd.concat([top_row, df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:44:46.071331Z",
     "start_time": "2021-04-01T08:44:46.065177Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['marketplace', 'product_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T23:07:44.269253Z",
     "start_time": "2021-03-31T23:07:44.263954Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = df[~df['review_body'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:20:55.930965Z",
     "start_time": "2021-04-01T09:20:55.900265Z"
    }
   },
   "outputs": [],
   "source": [
    "# considering people who only write headlines\n",
    "df['review_body'] = df['review_headline'] + '. ' + df['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:45:55.135976Z",
     "start_time": "2021-04-01T08:45:55.129276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15659"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:46:22.495780Z",
     "start_time": "2021-04-01T08:46:22.490451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:49:40.240689Z",
     "start_time": "2021-04-01T08:49:40.233574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        42521656\n",
       "1        12049833\n",
       "2          107642\n",
       "3         6042304\n",
       "4        18123821\n",
       "           ...   \n",
       "19995    14359560\n",
       "19996    23158903\n",
       "19997    16476066\n",
       "19998    52757565\n",
       "19999    17031304\n",
       "Name: customer_id, Length: 20000, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:52:21.297066Z",
     "start_time": "2021-04-01T08:52:21.290446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34247947    25\n",
       "20674418    18\n",
       "1535682     18\n",
       "13403431    17\n",
       "36290808    15\n",
       "            ..\n",
       "43931969     1\n",
       "49041728     1\n",
       "33367103     1\n",
       "52474172     1\n",
       "2686976      1\n",
       "Name: customer_id, Length: 15659, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['customer_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:47:50.471864Z",
     "start_time": "2021-04-01T08:47:50.457578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R3T1JWKO1X6EDL</td>\n",
       "      <td>B000F4GPC8</td>\n",
       "      <td>89439274</td>\n",
       "      <td>Miso-Cup Soup with Seaweed, 2-Serving Envelope...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Old stand by that is delicious</td>\n",
       "      <td>Old stand by that is delicious. Perfect and ea...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R1HC2YQHOSLX3Z</td>\n",
       "      <td>B000ILILLQ</td>\n",
       "      <td>539104877</td>\n",
       "      <td>Pamela's Simplebites Mini Cookies</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Too Good if you know what i mean.</td>\n",
       "      <td>Too Good if you know what i mean.. Too good. I...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R12FY3F7R3LT3</td>\n",
       "      <td>B008X60YEA</td>\n",
       "      <td>718531235</td>\n",
       "      <td>Twinings Earl Grey Tea, Keurig K-Cups, 24 Count</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>The best of all the non milky chai's</td>\n",
       "      <td>The best of all the non milky chai's. My favor...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1403</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R4NBEEFMHKPQ9</td>\n",
       "      <td>B00503DQIA</td>\n",
       "      <td>814285931</td>\n",
       "      <td>Silk Almond Milk</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Dark chocolate without any guilt.</td>\n",
       "      <td>Dark chocolate without any guilt.. Dark chocol...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R1TGM0S9T9GN3G</td>\n",
       "      <td>B00509LVIQ</td>\n",
       "      <td>138680402</td>\n",
       "      <td>Mauna Loa Macadamias, 11 Ounce Packages</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>In small amounts these are great, too many and...</td>\n",
       "      <td>In small amounts these are great, too many and...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1724</td>\n",
       "      <td>52646512</td>\n",
       "      <td>R1WU295CBZ8DC2</td>\n",
       "      <td>B008YDVYGO</td>\n",
       "      <td>267956568</td>\n",
       "      <td>San Francisco Bay One Cup</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>One of if not the best expresso pods for the K...</td>\n",
       "      <td>One of if not the best expresso pods for the K...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2738</td>\n",
       "      <td>52646512</td>\n",
       "      <td>RLM2HHPTV92P</td>\n",
       "      <td>B00IZJ8FWI</td>\n",
       "      <td>902799879</td>\n",
       "      <td>Grove Square Pumpkin Spice Cappuccino K-Cups (...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>5 stars if these were healthy.</td>\n",
       "      <td>5 stars if these were healthy.. The best of th...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id       review_id  product_id  product_parent  \\\n",
       "60       52646512  R3T1JWKO1X6EDL  B000F4GPC8        89439274   \n",
       "142      52646512  R1HC2YQHOSLX3Z  B000ILILLQ       539104877   \n",
       "171      52646512   R12FY3F7R3LT3  B008X60YEA       718531235   \n",
       "1403     52646512   R4NBEEFMHKPQ9  B00503DQIA       814285931   \n",
       "1637     52646512  R1TGM0S9T9GN3G  B00509LVIQ       138680402   \n",
       "1724     52646512  R1WU295CBZ8DC2  B008YDVYGO       267956568   \n",
       "2738     52646512    RLM2HHPTV92P  B00IZJ8FWI       902799879   \n",
       "\n",
       "                                          product_title  star_rating  \\\n",
       "60    Miso-Cup Soup with Seaweed, 2-Serving Envelope...            5   \n",
       "142                   Pamela's Simplebites Mini Cookies            5   \n",
       "171     Twinings Earl Grey Tea, Keurig K-Cups, 24 Count            5   \n",
       "1403                                   Silk Almond Milk            5   \n",
       "1637            Mauna Loa Macadamias, 11 Ounce Packages            5   \n",
       "1724                          San Francisco Bay One Cup            5   \n",
       "2738  Grove Square Pumpkin Spice Cappuccino K-Cups (...            4   \n",
       "\n",
       "      helpful_votes  total_votes vine verified_purchase  \\\n",
       "60                0            0    N                 Y   \n",
       "142               0            0    N                 Y   \n",
       "171               0            0    N                 Y   \n",
       "1403              0            0    N                 Y   \n",
       "1637              0            0    N                 Y   \n",
       "1724              0            0    N                 Y   \n",
       "2738              0            1    N                 Y   \n",
       "\n",
       "                                        review_headline  \\\n",
       "60                       Old stand by that is delicious   \n",
       "142                   Too Good if you know what i mean.   \n",
       "171                The best of all the non milky chai's   \n",
       "1403                  Dark chocolate without any guilt.   \n",
       "1637  In small amounts these are great, too many and...   \n",
       "1724  One of if not the best expresso pods for the K...   \n",
       "2738                     5 stars if these were healthy.   \n",
       "\n",
       "                                            review_body review_date  \n",
       "60    Old stand by that is delicious. Perfect and ea...  2015-08-31  \n",
       "142   Too Good if you know what i mean.. Too good. I...  2015-08-31  \n",
       "171   The best of all the non milky chai's. My favor...  2015-08-31  \n",
       "1403  Dark chocolate without any guilt.. Dark chocol...  2015-08-31  \n",
       "1637  In small amounts these are great, too many and...  2015-08-31  \n",
       "1724  One of if not the best expresso pods for the K...  2015-08-31  \n",
       "2738  5 stars if these were healthy.. The best of th...  2015-08-31  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['customer_id'] == 52646512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:55:43.688972Z",
     "start_time": "2021-04-01T08:55:43.651848Z"
    }
   },
   "outputs": [],
   "source": [
    "# combining customer id + product id\n",
    "df['customer_product'] = df['customer_id'].astype(str) + '_' + df['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:55:44.775683Z",
     "start_time": "2021-04-01T08:55:44.747457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendaduan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# check if there exists any user reviewed one product twice\n",
    "df['customer_product'].value_counts().to_csv('customer_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T08:56:10.210003Z",
     "start_time": "2021-04-01T08:56:10.179301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>customer_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [customer_id, review_id, product_id, product_parent, product_title, star_rating, helpful_votes, total_votes, vine, verified_purchase, review_headline, review_body, review_date, customer_product]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the same one\n",
    "df[df['customer_product'] == '13879735_B003WO0I6C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:03:04.752205Z",
     "start_time": "2021-04-01T09:03:04.738104Z"
    }
   },
   "outputs": [],
   "source": [
    "customer_rate_mean = df.groupby(['customer_id'])['star_rating'].mean()\n",
    "customer_rate_count = df['customer_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:03:05.146231Z",
     "start_time": "2021-04-01T09:03:05.137926Z"
    }
   },
   "outputs": [],
   "source": [
    "# star rating average of each customer\n",
    "customer_rate_mean = customer_rate_mean.reset_index()\n",
    "customer_rate_mean.columns = ['customer_id', 'rating']\n",
    "\n",
    "# how many reviews does each customer write\n",
    "customer_rate_count = customer_rate_count.reset_index()\n",
    "customer_rate_count.columns = ['customer_id', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:03:07.337529Z",
     "start_time": "2021-04-01T09:03:07.332351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['customer_id', 'rating'], dtype='object'),\n",
       " Index(['customer_id', 'count'], dtype='object'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_rate_mean.columns, customer_rate_count.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:04:34.331105Z",
     "start_time": "2021-04-01T09:04:34.316493Z"
    }
   },
   "outputs": [],
   "source": [
    "# merging rating average and review counts into one table\n",
    "customer_df = pd.merge(customer_rate_mean, customer_rate_count, on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:05:15.223530Z",
     "start_time": "2021-04-01T09:05:15.210280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9777</td>\n",
       "      <td>34247947</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6374</td>\n",
       "      <td>20674418</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>1535682</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3691</td>\n",
       "      <td>13403431</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9648</td>\n",
       "      <td>33718153</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5651</td>\n",
       "      <td>18135902</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5652</td>\n",
       "      <td>18144169</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5653</td>\n",
       "      <td>18147763</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5654</td>\n",
       "      <td>18147977</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15658</td>\n",
       "      <td>53094990</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id    rating  count\n",
       "9777      34247947  4.960000     25\n",
       "6374      20674418  5.000000     18\n",
       "747        1535682  4.888889     18\n",
       "3691      13403431  4.882353     17\n",
       "9648      33718153  5.000000     15\n",
       "...            ...       ...    ...\n",
       "5651      18135902  4.000000      1\n",
       "5652      18144169  5.000000      1\n",
       "5653      18147763  5.000000      1\n",
       "5654      18147977  5.000000      1\n",
       "15658     53094990  4.000000      1\n",
       "\n",
       "[15659 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:05:56.391904Z",
     "start_time": "2021-04-01T09:05:56.379838Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "customer_df[(customer_df['rating'] <=3) & (customer_df['count'] >= 2)].sort_values(by='count', ascending=False).to_csv('review_counts_for_each_user.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the suspicious reviews\n",
    "select_customer = customer_df[(customer_df['count'] >= 2) & (customer_df['rating'] <=3)]['customer_id']\n",
    "\n",
    "df[df['customer_id'].isin(select_customer)][['customer_id','star_rating','review_headline', 'review_body']].sort_values(by='customer_id').to_csv('suspicious_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T22:54:05.192586Z",
     "start_time": "2021-03-31T22:54:05.185816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9        Disgusting now and difficult on digestion. Use...\n",
       "17       1 Out Of 5 Of My Co-Workers Thought It Was \"Ok...\n",
       "23       pita crackers. not craze about these. nothing ...\n",
       "40       Does not recommend!. This product is beautiful...\n",
       "99       It's actually TOO salty.. Not what I expected....\n",
       "                               ...                        \n",
       "19923    Made the Pinot Grigio and I would say don't wa...\n",
       "19924    Changed product to something unacceptably infe...\n",
       "19954                         One Star. Way too expensive.\n",
       "19971                     One Star. I order 6 i received 4\n",
       "19978    yuck!. I did not like at all. I know it's seaw...\n",
       "Name: review_body, Length: 1451, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['star_rating'] == 1]['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T22:57:01.327112Z",
     "start_time": "2021-03-31T22:56:56.226069Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective ‘big’\n",
    "JJR adjective, comparative ‘bigger’\n",
    "JJS adjective, superlative ‘biggest’\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular ‘desk’\n",
    "NNS noun plural ‘desks’\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "PDT predeterminer ‘all the kids’\n",
    "POS possessive ending parent’s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO, to go ‘to’ the store.\n",
    "UH interjection, errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense, took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle is taken\n",
    "VBP verb, sing. present, known-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-adverb where, when\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:08:43.875504Z",
     "start_time": "2021-04-01T09:08:43.866570Z"
    }
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/brendaduan/nltk_data'\n    - '/Users/brendaduan/anaconda3/nltk_data'\n    - '/Users/brendaduan/anaconda3/share/nltk_data'\n    - '/Users/brendaduan/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-13face5aea77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://www.nltk.org/book/ch05.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# part of speech\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mushrooms are moldy!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     return [\n\u001b[1;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/brendaduan/nltk_data'\n    - '/Users/brendaduan/anaconda3/nltk_data'\n    - '/Users/brendaduan/anaconda3/share/nltk_data'\n    - '/Users/brendaduan/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# https://www.nltk.org/book/ch05.html\n",
    "# part of speech\n",
    "tokens = nltk.word_tokenize('Mushrooms are moldy!')\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:09:47.863012Z",
     "start_time": "2021-04-01T09:09:47.858260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mushrooms', 'are', 'moldy', '!']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1925: expected 15 fields, saw 22\\nSkipping line 1977: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "df_s = pd.read_csv('amazon_reviews_us_Grocery_v1_00.tsv.gz', \n",
    "                 nrows=20000, sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T23:07:49.042893Z",
     "start_time": "2021-03-31T23:07:48.981084Z"
    }
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/brendaduan/nltk_data'\n    - '/Users/brendaduan/anaconda3/nltk_data'\n    - '/Users/brendaduan/anaconda3/share/nltk_data'\n    - '/Users/brendaduan/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9c81e03dbd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<br />'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrags_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     return [\n\u001b[1;32m    146\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/brendaduan/nltk_data'\n    - '/Users/brendaduan/anaconda3/nltk_data'\n    - '/Users/brendaduan/anaconda3/share/nltk_data'\n    - '/Users/brendaduan/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# take the adjs from the comments with 1 star\n",
    "#for line in df[df['star_rating'] == 1]['review_body']:\n",
    "for line in df_s['review_body']:\n",
    "    line = line.replace('<br />', '')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    rags_select = []\n",
    "    for tag in tags:\n",
    "        if tag[1] in ['JJ', 'JJR', 'JJS', 'VBG']:\n",
    "            rags_select.append(tag[0])\n",
    "    \n",
    "    print(line)\n",
    "    print(rags_select)\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:12:17.956854Z",
     "start_time": "2021-04-01T09:12:17.947351Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The titular threat of The Blob has always struck me as the ultimate movie\n",
      "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
      "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
      "describes it--\"assimilating flesh on contact. 0.06000000000000001 0.605\n",
      "\n",
      "Snide comparisons to gelatin be damned, it's a concept with the most\n",
      "devastating of potential consequences, not unlike the grey goo scenario\n",
      "proposed by technological theorists fearful of\n",
      "artificial intelligence run rampant. -0.34166666666666673 0.7666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# https://textblob.readthedocs.io/en/dev/\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    # sentence.sentiment.polarity\n",
    "    # sentence.sentiment.subjectivity \n",
    "    print(sentence, sentence.sentiment.polarity, sentence.sentiment.subjectivity)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T23:31:20.220478Z",
     "start_time": "2021-03-31T23:31:20.149449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used to be a decent product. 0.16666666666666666 0.6666666666666666\n",
      "\n",
      "Disgusting now and difficult on digestion. -0.75 1.0\n",
      "\n",
      "All 3 purchased from Costco over past couple months end in same result -- open the container and it smells like rancid oil. -0.08333333333333333 0.2916666666666667\n",
      "\n",
      "Something not right about how they are making/processing this powder now. -0.14285714285714285 0.5357142857142857\n",
      "\n",
      "Will not buy again. 0.0 0.0\n",
      "\n",
      "\n",
      "I bought this from a local super market on a whim and decided to let people know how it tastes. 0.16666666666666666 0.3333333333333333\n",
      "\n",
      "I'm a huge fan of peanut butter and salted caramel.For instance, I had a Salted Caramel and Almond Kind Bar today and it was amazing. 0.5333333333333333 0.9\n",
      "\n",
      "It tasted like you would expect it to taste.However, this particular product tastes like a chemical spill. 0.16666666666666666 0.3333333333333333\n",
      "\n",
      "It starts off with a peanut butter taste, but then the (caramel I'm guessing) tastes kind of burnt and chemical-like, and then it finishes with a very salty burnt taste.I had some on a spoon and disliked it, then I put some on pretzel bread and it was slightly palatable, but overall I would avoid this product as it doesn't really taste like salted caramel peanut butter.Just for fun, I let my co-workers taste it and only 1 out of 5 of them thought that this product tasted &#34;okay&#34;. 0.1166666666666667 0.42083333333333334\n",
      "\n",
      "The rest of them shared my sentiment. 0.0 0.0\n",
      "\n",
      "\n",
      "not craze about these. 0.0 0.0\n",
      "\n",
      "nothing really wrong with them just no into them. -0.5 0.9\n",
      "\n",
      "These crackers are small so not much room for cheese. -0.175 0.30000000000000004\n",
      "\n",
      "\n",
      "This product is beautifully labelled. 0.85 1.0\n",
      "\n",
      "That's about all there is to it. 0.0 0.0\n",
      "\n",
      "The actual taste is not consistent with the flavor the label claims to represent. -0.0625 0.175\n",
      "\n",
      "Just a very pretty bottle. 0.325 1.0\n",
      "\n",
      "The good news is that the failure of this product to meet my expectation served as the impetus for me to make my own syrups. 0.3277777777777777 0.6333333333333334\n",
      "\n",
      "Real fruit juice + Sugar 0.2 0.30000000000000004\n",
      "\n",
      "\n",
      "Not what I expected. -0.1 0.4\n",
      "\n",
      "Did not like it at all. 0.0 0.0\n",
      "\n",
      "\n",
      "These use to be the best tasting bars on the market; I had one for breakfast for a good part of 5 years. 0.85 0.45000000000000007\n",
      "\n",
      "But Powerbar changed the formula or something and now they are just awful. -1.0 1.0\n",
      "\n",
      "Additionally they were 2.29-Ounce but the new packaging has them at 1.58-Ounce Bars. 0.13636363636363635 0.45454545454545453\n",
      "\n",
      "I switched to Cliff bars. 0.0 0.0\n",
      "\n",
      "\n",
      "These dates were very old upon arrival, and for the most part dry and tasteless. -0.009166666666666656 0.565\n",
      "\n",
      "No where on the packaging dos it state they are organic. 0.0 0.0\n",
      "\n",
      "Don't be fooled by the great price! 1.0 0.75\n",
      "\n",
      "\n",
      "I noticed the words 1g Sugar and bought this on the spot at a health food store, believing it was just low sugar but after reading the ingredients at home, I had to drive a long way to return it because it had sucralose in it. -0.025 0.35\n",
      "\n",
      "With sucralose, this is not a health bar. 0.0 0.0\n",
      "\n",
      "It is on the same level as nutrasweet and causes severe reactions in some people including myself. 0.0 0.125\n",
      "\n",
      "There is nothing healthy about sucralose. 0.5 0.5\n",
      "\n",
      "Stevia is a very healthy and great tasting alternative and natural sweetener but extremely hard to find in current products and if the so-called health food companies would just use it, then it could be called healthy. 0.29305555555555557 0.5402777777777777\n",
      "\n",
      "Also, Saccharin is a very good sweetener that has been given a bad rap for years by the FDA for supposedly causing cancer but has never been proven. 0.10500000000000004 0.7233333333333334\n",
      "\n",
      "I have used &#34;Sweet & Low&#34; daily for over 35 years in my coffee, tea, cereal, etc. 0.0 0.0\n",
      "\n",
      "and have had virtually no reactions ever and am cancer free! 0.5 0.8\n",
      "\n",
      "Other countries don't want America's health foods because of the awful, unhealthy ingredients. -0.5083333333333333 0.6916666666666668\n",
      "\n",
      "The FDA should demand that products containing splenda and nutrasweet have bold lettering on the package warning consumers. 0.3333333333333333 0.6666666666666666\n",
      "\n",
      "Shame on atkins. 0.0 0.0\n",
      "\n",
      "Thanks 0.2 0.2\n",
      "\n",
      "\n",
      "Es puro azucar, no tiene sabor a cas. 0.0 0.0\n",
      "\n",
      "\n",
      "thru it out  stale -0.5 0.5\n",
      "\n",
      "\n",
      "This item was a total joke!! 0.0 0.75\n",
      "\n",
      "5G??? 0.0 0.0\n",
      "\n",
      "It only covered 4 cookies!!! 0.0 1.0\n",
      "\n",
      "Also it tasted terrible....AND it was NOT navy, it was royal blue!!! 0.0 0.1\n",
      "\n",
      "Stay clear of this&#34;tiny dab&#34; of glitter!!!! 0.24414062500000003 0.3833333333333333\n",
      "\n",
      "! 0.0 0.0\n",
      "\n",
      "\n",
      "I bought this product at a grocery. 0.0 0.0\n",
      "\n",
      "Its no different than amazon would send. 0.0 0.6\n",
      "\n",
      "I use a Cuisinart k-cup brewer with Keurig core. 0.0 0.0\n",
      "\n",
      "Seattle's Best House Blend K-cups in my unit yield 4 oz's when the unit is set to brew 8. 1.0 0.3\n",
      "\n",
      "And sometimes it won't brew at all. 0.0 0.0\n",
      "\n",
      "I've had nothing like this problem with any other k-cup (Green Mountain, Starbucks, Marley, Lavazza, various Kona's). -0.10833333333333334 0.39166666666666666\n",
      "\n",
      "I disassembled one k-cup and it looks like the problem may be the fineness of the grind. 0.0 0.0\n",
      "\n",
      "Once its wet it forms an impenetrable block. -0.1 0.4\n",
      "\n",
      "I can't comment on what this coffee tastes like because I haven't able to brew a fair cup to sample. 0.6 0.7625\n",
      "\n",
      "\n",
      "Expensive -0.5 0.7\n",
      "\n",
      "\n",
      "there are absolutely no instructions or recipes on pkg -0.1 0.9\n",
      "\n",
      "\n",
      "I loved the old formula. 0.39999999999999997 0.5\n",
      "\n",
      "I sang Zevia's praises to whomever would listen. 0.0 0.0\n",
      "\n",
      "I ordered by the multiple cases. 0.0 0.0\n",
      "\n",
      "And then, they decided to go non-GMO. 0.0 0.0\n",
      "\n",
      "That's usually a good thing. 0.7 0.6000000000000001\n",
      "\n",
      "Unfortunately, the new formulas are just awful. -0.4545454545454546 0.8181818181818182\n",
      "\n",
      "And, somehow, they managed to wreck the fizz. 0.0 0.0\n",
      "\n",
      "THE FIZZ! 0.0 0.0\n",
      "\n",
      "The new formulas go flat very quickly, especially with ice. 0.03712121212121212 0.5265151515151515\n",
      "\n",
      "Please, Zevia, bring back the old formulas! 0.0625 0.1\n",
      "\n",
      "Now I'm off to buy Blue Sky, which had been the inferior brand but is now the only option left. 0.0 0.3666666666666667\n",
      "\n",
      "\n",
      "I have ordered these coffee pods many times. 0.5 0.5\n",
      "\n",
      "when my husband tasted the latest batch, he said that it really lacked in flavor.When our houseguests said the same thing, I decided to post this warning. 0.2333333333333333 0.4083333333333334\n",
      "\n",
      "I am sending back the remaining boxes. 0.0 0.0\n",
      "\n",
      "\n",
      "I got excited when I saw this toddler meal as it sounds just what my baby would love to eat (we are going on a 18 hour flight so I'm looking for snacks and meals for him.) 0.4375 0.675\n",
      "\n",
      "I ordered some of these, only to realize it has PARTIALLY HYDROGENATED SOYBEAN OIL. -0.05 0.65\n",
      "\n",
      "Really?! 0.25 0.2\n",
      "\n",
      "Do you need carcinogens in a toddler meal?! 0.0 0.0\n",
      "\n",
      "And the soybean oil is probably GMO too, as I noticed (too late) it didn't say it wasn't.Thanks but no thanks. -0.2 0.4\n",
      "\n",
      "My baby is not eating this. 0.0 0.0\n",
      "\n",
      "\n",
      "The chocolate was white and tasted old. 0.05 0.1\n",
      "\n",
      "I could not eat them and threw them away. 0.0 0.0\n",
      "\n",
      "\n",
      "I had to throw away one 8 pack of this juice because it was moldy and I didn't want to unwrap the pack and be exposed to the mold. 0.0 0.0\n",
      "\n",
      "Not sure why this happened. -0.25 0.8888888888888888\n",
      "\n",
      "I had purchased this product before and been very happy. 1.0 1.0\n",
      "\n",
      "\n",
      "The marshmallow bags were difficult to open. -0.25 0.75\n",
      "\n",
      "The marshmallows were melted and stuck not only to themselves but the bags. 0.0 1.0\n",
      "\n",
      "These were meant to be added to a snack mix for a child's birthday party. 0.0 0.0\n",
      "\n",
      "I was unable to use them because they were one/a few big globs of marshmallow and because of that they did not resemble ice cream cones nor did they work for the snack mix. -0.2333333333333333 0.2333333333333333\n",
      "\n",
      "Very disappointed. -0.9750000000000001 0.9750000000000001\n",
      "\n",
      "\n",
      "why does the reese's company lie to us? 0.0 0.0\n",
      "\n",
      "it is not the peanut butter in the reese's peanut butter cup. 0.0 0.0\n",
      "\n",
      "\n",
      "It was 3 days before its expiration date and yep, tasted stale. -0.5 0.5\n",
      "\n",
      "\n",
      "My goal was to try and match a Starbucks Vanilla Latte, and unfortunately this tasted nothing like it. -0.5 1.0\n",
      "\n",
      "Would not buy again. 0.0 0.0\n",
      "\n",
      "\n",
      "Poor quality and quantity, think small then think smaller. -0.21666666666666667 0.5\n",
      "\n",
      "Looking for kids lunches and this was not the right fit at all. 0.34285714285714286 0.46785714285714286\n",
      "\n",
      "\n",
      "Very Disappointed with this product. -0.9750000000000001 0.9750000000000001\n",
      "\n",
      "Packagaing stated 48 bars, 8 of each type. 0.0 0.0\n",
      "\n",
      "We received 42 bars, NO strawberry and 10 grape. 0.0 0.0\n",
      "\n",
      "Would NOT buy this again or recommend it to others! 0.0 0.0\n",
      "\n",
      "\n",
      "Product was not as described:  The description is for dark chocolate with almonds, but I received only a mixture of various kinds of bars (caramel, crunch, etc.) -0.049999999999999996 0.6333333333333333\n",
      "\n",
      "-- but NONE with almonds. 0.0 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in df[df['star_rating'] == 1]['review_body']:\n",
    "    line = line.replace('<br />', '')\n",
    "    \n",
    "    blob = TextBlob(line)\n",
    "    for sentence in blob.sentences:\n",
    "        print(sentence, sentence.sentiment.polarity, sentence.sentiment.subjectivity)\n",
    "        print('')\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T23:35:04.140765Z",
     "start_time": "2021-03-31T23:35:04.085357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disgusting now and difficult on digestion. -0.75 1.0\n",
      "\n",
      "All 3 purchased from Costco over past couple months end in same result -- open the container and it smells like rancid oil. -0.08333333333333333 0.2916666666666667\n",
      "\n",
      "Something not right about how they are making/processing this powder now. -0.14285714285714285 0.5357142857142857\n",
      "\n",
      "\n",
      "\n",
      "nothing really wrong with them just no into them. -0.5 0.9\n",
      "\n",
      "These crackers are small so not much room for cheese. -0.175 0.30000000000000004\n",
      "\n",
      "\n",
      "The actual taste is not consistent with the flavor the label claims to represent. -0.0625 0.175\n",
      "\n",
      "\n",
      "Not what I expected. -0.1 0.4\n",
      "\n",
      "\n",
      "But Powerbar changed the formula or something and now they are just awful. -1.0 1.0\n",
      "\n",
      "\n",
      "These dates were very old upon arrival, and for the most part dry and tasteless. -0.009166666666666656 0.565\n",
      "\n",
      "\n",
      "I noticed the words 1g Sugar and bought this on the spot at a health food store, believing it was just low sugar but after reading the ingredients at home, I had to drive a long way to return it because it had sucralose in it. -0.025 0.35\n",
      "\n",
      "Other countries don't want America's health foods because of the awful, unhealthy ingredients. -0.5083333333333333 0.6916666666666668\n",
      "\n",
      "\n",
      "\n",
      "thru it out  stale -0.5 0.5\n",
      "\n",
      "\n",
      "\n",
      "I've had nothing like this problem with any other k-cup (Green Mountain, Starbucks, Marley, Lavazza, various Kona's). -0.10833333333333334 0.39166666666666666\n",
      "\n",
      "Once its wet it forms an impenetrable block. -0.1 0.4\n",
      "\n",
      "\n",
      "Expensive -0.5 0.7\n",
      "\n",
      "\n",
      "there are absolutely no instructions or recipes on pkg -0.1 0.9\n",
      "\n",
      "\n",
      "Unfortunately, the new formulas are just awful. -0.4545454545454546 0.8181818181818182\n",
      "\n",
      "\n",
      "\n",
      "I ordered some of these, only to realize it has PARTIALLY HYDROGENATED SOYBEAN OIL. -0.05 0.65\n",
      "\n",
      "And the soybean oil is probably GMO too, as I noticed (too late) it didn't say it wasn't.Thanks but no thanks. -0.2 0.4\n",
      "\n",
      "\n",
      "\n",
      "Not sure why this happened. -0.25 0.8888888888888888\n",
      "\n",
      "\n",
      "The marshmallow bags were difficult to open. -0.25 0.75\n",
      "\n",
      "I was unable to use them because they were one/a few big globs of marshmallow and because of that they did not resemble ice cream cones nor did they work for the snack mix. -0.2333333333333333 0.2333333333333333\n",
      "\n",
      "Very disappointed. -0.9750000000000001 0.9750000000000001\n",
      "\n",
      "\n",
      "\n",
      "It was 3 days before its expiration date and yep, tasted stale. -0.5 0.5\n",
      "\n",
      "\n",
      "My goal was to try and match a Starbucks Vanilla Latte, and unfortunately this tasted nothing like it. -0.5 1.0\n",
      "\n",
      "\n",
      "Poor quality and quantity, think small then think smaller. -0.21666666666666667 0.5\n",
      "\n",
      "\n",
      "Very Disappointed with this product. -0.9750000000000001 0.9750000000000001\n",
      "\n",
      "\n",
      "Product was not as described:  The description is for dark chocolate with almonds, but I received only a mixture of various kinds of bars (caramel, crunch, etc.) -0.049999999999999996 0.6333333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in df[df['star_rating'] == 1]['review_body']:\n",
    "    line = line.replace('<br />', '')\n",
    "    \n",
    "    blob = TextBlob(line)\n",
    "    for sentence in blob.sentences:\n",
    "        if sentence.sentiment.polarity >= 0:\n",
    "            continue\n",
    "            \n",
    "        print(sentence, sentence.sentiment.polarity, sentence.sentiment.subjectivity)\n",
    "        print('')\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
